<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        
        <meta name="keywords" content="OpenMMLab, Chen Change Loy, Ziwei Liu, Bo Dai, Yixin Cao, Super-resolution, Deep Learning, Computer Vision, Convolutional Neural Network, Enhancement, Inpainting, Knowledge Distillation, Restoration, GAN, Generative Adversarial Networks, Generation, Manipulation, Editing, Object Detection, Segmentation, Recognition, Continual Learning, Domain Generalization, Self-Supervised Learning, Singapore, NTU, Nanyang Technological University, SCSE" />
        
        <!-- Page Title -->
        <title>CVPR 2021 Accepted Papers | MMLab@NTU</title>

        <!-- Favicons -->
        <link rel="apple-touch-icon" sizes="180x180" href="../../assets/img/favicons/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="../../assets/img/favicons/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="../../assets/img/favicons/favicon-16x16.png">
        <link rel="manifest" href="../../assets/img/favicons/site.webmanifest">
        <link rel="mask-icon" href="../../assets/img/favicons/safari-pinned-tab.svg" color="#f23838">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">

        <!-- Vendor Stylesheets -->
        <link href="https://fonts.googleapis.com/css?family=Oswald:300,400,500,700%7CRoboto:300,400,700" rel="stylesheet">
        <link href="../../assets/vendor/material-design-iconic-font/dist/css/material-design-iconic-font.min.css" rel="stylesheet">
        <link href="../../assets/vendor/@fancyapps/fancybox/dist/jquery.fancybox.min.css" rel="stylesheet">
        <link href="../../assets/vendor/aos/dist/aos.css" rel="stylesheet">

        <!-- Theme Stylesheets -->
        <link href="../../assets/css/theme.css" rel="stylesheet">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-22940424-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-22940424-1');
        </script>
    </head>

    <body>
        <!-- Preloader -->
        <div class="preloader">
            <div class="spinner">
                <div class="circles"></div>
            </div>
        </div>
        <!-- End of Preloader -->


        <!-- Header -->
        <header class="spyre-navbar navbar navbar-expand-lg bg-secondary navbar-dark fixed-top align-items-center" data-transparent data-text-color="#ffffff">
            <div class="container">
                <a class="navbar-brand mr-lg-5 mr-xl-7" href="../../index.html">
                    <img src="../../assets/img/logo.png" class="d-none d-lg-block" alt="MMLab" width="183" />
                    <img src="../../assets/img/logo.png" class="d-block d-lg-none" alt="MMLab" width="150" />
                </a>

                <!-— Desktop Menu -->
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="navbar-nav mr-auto">
                        <li class="pl-2 nav-item navbar-text"><a href="../../index.html" class="nav-link text-400">Home</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="../../team.html" class="nav-link text-400">Team</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="../../research.html" class="nav-link text-400">Research</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="../../publication_topic.html" class="nav-link text-400">Publications</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="../../downloads.html" class="nav-link text-400">Code | Datasets</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="../../careers.html" class="nav-link text-400">Join Us</a></li>
                    </ul>
                </div>
                <!-— End of Desktop Menu -->

                <div class="menu-toggle d-block d-lg-none">
                    <div class="hamburger">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                    <div class="cross">
                        <span></span>
                        <span></span>
                    </div>
                </div>
            </div>

            <!-- Spyrenav Overlay -->
            <div class="spyre-navbar-overlay overlay-slide">
                <div class="container">
                    <div class="row">
                        <div class="spyre-navbar-nav-container col-md-6 col-lg-5 col-xl-4 bg-white ext-l">
                            <nav class="spyre-navbar-nav">
                                <ul class="spyre-nav">
                                    <li class="spyre-nav-item"><a href="../../index.html" class="spyre-nav-link">Home</a></li>
                                    <li class="spyre-nav-item"><a href="../../research.html" class="spyre-nav-link">Our Research</a></li>
                                    <li class="spyre-nav-item"><a href="../../team.html" class="spyre-nav-link">Team</a></li>
                                    <li class="spyre-nav-item dropdown">
                                        <a href="#" class="spyre-nav-link dropdown-toggle" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications</a>
                                        <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                                            <li class="dropdown-menu-item"><a href="../../publication_topic.html" class="dropdown-menu-link">By Topic</a></li>
                                            <li class="dropdown-menu-item"><a href="../../publication_year.html" class="dropdown-menu-link">By Year</a></li>
                                        </ul>
                                    </li>
                                    <li class="spyre-nav-item"><a href="../../downloads.html" class="spyre-nav-link">Codes and Datasets</a></li>
                                    <li class="spyre-nav-item"><a href="../../careers.html" class="spyre-nav-link">Join Us</a></li>
                                </ul>
                            </nav>
                        </div>
        
                        <div class="col-lg-7 col-xl-8 d-none d-md-block">
                            <div class="d-flex flex-column h-100">
                                <div class="d-flex h-100">
                                    <div class="align-self-center">
                                        <div class="text-uppercase"
                                            data-background-text="computer vision"
                                            data-color="#7079a2"
                                            data-opacity="0.02"
                                            data-font-size="85px"
                                            data-font-weight="500"
                                            data-offset-x="-5%"
                                            data-letter-spacing="5px"
                                        ></div>
                                        <div class="text-uppercase"
                                            data-background-text="mmlab"
                                            data-color="#7079a2"
                                            data-opacity="0.04"
                                            data-font-size="175px"
                                            data-font-weight="500"
                                            data-offset-x="29%"
                                            data-padding="7vh 0 2vh 0"
                                            data-letter-spacing="5px"
                                        ></div>
                                        <div class="text-uppercase"
                                            data-background-text="deep learning"
                                            data-color="#7079a2"
                                            data-opacity="0.03"
                                            data-font-size="140px"
                                            data-font-weight="500"
                                            data-offset-x="15%"
                                            data-letter-spacing="5px"
                                        ></div>
                                    </div>
                                </div>
                                
                                <div class="mt-auto">
                                    <ul class="nav flex-nowrap float-right">
                                        <li class="nav-item">
                                            <a class="nav-link px-2" href="https://twitter.com/MMLabNTU" target="_blank">
                                                <i class="zmdi zmdi-twitter text-white"></i>
                                            </a>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <!-- End of Spyrenav Overlay -->
        </header>
        <!-- End of Header -->


        <!-- Main Content -->
        <main class="main minh-100vh">
            <!-- Section -->
            <section class="py-0 overflow-hidden text-center">
                <div class="bg-container overlay overlay-60 parallax" data-rellax-percentage="0.5" style="background-image: url(../../assets/img/images/cvpr_2021.jpg)"></div>
                <div class="container">
                    <div class="row h-100vh justify-content-center align-items-center">
                        <div class="col-lg-8">
                            <h1 class="text-white fs-5 fs-lg-7" data-aos="fade-left" data-aos-duration="500">CVPR 2021</h1>
                            <p class="mb-0 fs-lg-1 text-white" data-aos="fade-right" data-aos-delay="50" data-aos-duration="500">Presentation Schedule     
                            </p>
                        </div>

                        <div class="move d-none d-lg-block">
                            <a href="#section-1" class="text-white" data-smooth-scroll data-smooth-scroll-hash="false">
                                <i class="zmdi zmdi-long-arrow-down zmdi-hc-2x"></i>
                            </a>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->           

            <!-- Section -->
            <section id="section-1" class="pt-6 pb-3">
                <div class="container">
                    <div class="row">
                        <div class="col">
                            <h3 class="my-0 fs-1 fw-medium text-secondary text-uppercase text-center">Presentation</h3>
                            <h2 class="mb-4 fw-medium text-primary text-uppercase text-center">Schedule</h2>
                            <p class="text-500 text-center">The team has a total of 18 papers accepted to CVPR 2021 (including four orals). Eastern Daylight Time is 12 hours behind of Singapore Time.</p>
                        </div>
                    </div>
                    <div>
                        <table class="table table-responsive-sm">
                            <thead class="bg-secondary text-white">
                                <th>Eastern Daylight Time</th><th>Session</th><th>Paper</th>
                            </thead>
                            <tbody>
                            <tr>
                                <td><strong>Monday, June 21 <br /> 11:00 – 13:30</strong></td>
                                <td>One</td>
                                <td>
                                <span class="text-primary">Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Network </span> 
                                <br />
                                <span class="text-500">
                                R. Feng, C. Li, H. Chen, S. Li, C. C. Loy, J. Gu  <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Removing_Diffraction_Image_Artifacts_in_Under-Display_Camera_via_Dynamic_Skip_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.09556"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Feng_Removing_Diffraction_Image_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://jnjaby.github.io/projects/UDC/"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="3"><strong>Monday, June 21 <br /> 22:00  – 24:30</strong></td>
                                <td rowspan="3">Two</td>
                                <td>
                                <span class="text-primary">Robust Reference-based Super-Resolution via C<sup>2</sup>-Matching </span> 
                                <br />
                                <span class="text-500">
                                Y. Jiang, K. C. K. Chan, X. Wang, C. C. Loy, Z. Liu <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Robust_Reference-Based_Super-Resolution_via_C2-Matching_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2106.01863"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Jiang_Robust_Reference-Based_Super-Resolution_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://github.com/yumingj/C2-Matching"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Pareidolia Face Reenactment </span> 
                                <br />
                                <span class="text-500">
                                L. Song, W. Wu, C. Fu, C. Qian, C. C. Loy, R. He  <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Pareidolia_Face_Reenactment_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.03061"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Song_Pareidolia_Face_Reenactment_CVPR_2021_supplemental.zip"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://wywu.github.io/projects/ETT/ETT.html"><span class="text-muted">Project Page</span></a>]
                                [<a href="https://www.youtube.com/watch?v=lVYZ3IAVM_U"><span class="text-muted">YouTube</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Unsupervised 3D Shape Completion through GAN Inversion </span> 
                                <br />
                                <span class="text-500">
                                J. Zhang, X. Chen, Z. Cai, L. Pan, H. Zhao, S. Yi, C. K. Yeo, B. Dai, C. C. Loy <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Unsupervised_3D_Shape_Completion_Through_GAN_Inversion_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.13366"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Zhang_Unsupervised_3D_Shape_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://junzhezhang.github.io/projects/ShapeInversion/"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td><strong>Tuesday, June 22 <br /> 6:00– 8:30</strong></td>
                                <td>Three</td>
                                <td>
                                <span class="text-primary">Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation </span> 
                                <br />
                                <span class="text-500">
                                H. Zhou, Y. Sun, W. Wu, C. C. Loy, X. Wang, Z. Liu <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Pose-Controllable_Talking_Face_Generation_by_Implicitly_Modularized_Audio-Visual_Representation_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.11116"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Zhou_Pose-Controllable_Talking_Face_CVPR_2021_supplemental.zip"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="2"><strong>Tuesday, June 22 <br /> 11:00 – 13:30</strong></td>
                                <td rowspan="2">Four</td>
                                <td>
                                <span class="text-primary">BasicVSR: The Search for Essential Components in Video Super-Resolution and Beyond </span> 
                                <br />
                                <span class="text-500">
                                K. C. K. Chan, X. Wang, K. Yu, C. Dong, C. C. Loy <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2012.02181"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Chan_BasicVSR_The_Search_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://ckkelvinchan.github.io/projects/BasicVSR"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis </span> <strong>(Oral)</strong>
                                <br />
                                <span class="text-500">
                                Y. He, B. Gan, S. Chen, Y. Zhou, G. Yin, L. Song, L. Sheng, J. Shao, Z. Liu  <br /> 
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2103.05630"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/He_ForgeryNet_A_Versatile_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://yinanhe.github.io/projects/forgerynet.html"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td><strong>Tuesday, June 22 <br /> 22:00  – 24:30</strong></td>
                                <td>Five</td>
                                <td>
                                <span class="text-primary">Deep Animation Video Interpolation in the Wild </span> 
                                <br />
                                <span class="text-500">
                                S-Y. Li, S. Zhao, W. Yu, W. Sun, D. Metaxas, C. C. Loy, Z. Liu <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.02495"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Siyao_Deep_Animation_Video_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://github.com/lisiyao21/AnimeInterp/"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="3"><strong>Wednesday, June 23 <br /> 11:00 – 13:30</strong></td>
                                <td rowspan="3">Seven</td>
                                <td>
                                <span class="text-primary">Variational Relational Point Completion Network </span> <strong>(Oral)</strong>
                                <br />
                                <span class="text-500">
                                L. Pan, X. Chen, Z. Cai, J. Zhang, H. Zhao, S. Yi, Z. Liu <br />
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Variational_Relational_Point_Completion_Network_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.10154"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Pan_Variational_Relational_Point_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://paul007pl.github.io/projects/VRCNet"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Adversarial Robustness under Long-Tailed Distribution </span> <strong>(Oral)</strong>
                                <br />
                                <span class="text-500">
                                T. Wu, Z. Liu, Q. Huang, Y. Wang, D. Lin <br />
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Adversarial_Robustness_Under_Long-Tailed_Distribution_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.02703"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wu_Adversarial_Robustness_Under_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://github.com/wutong16/Adversarial_Long-Tail"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Seesaw Loss for Long-Tailed Instance Segmentation </span> 
                                <br />
                                <span class="text-500">
                                J. Wang, W. Zhang, Y. Zang, Y. Cao, J. Pang, T. Gong, K. Chen, Z. Liu, C. C. Loy, D. Lin  <br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Seesaw_Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2008.10032"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Seesaw_Loss_for_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="2"><strong>Thursday, June 24 <br /> 6:00– 8:30</strong></td>
                                <td rowspan="2">Nine</td>
                                <td>
                                <span class="text-primary">Unsupervised Feature Learning by Cross-Level Instance-Group Discrimination </span> 
                                <br />
                                <span class="text-500">
                                X. Wang, Z. Liu, S. X. Yu  <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Feature_Learning_by_Cross-Level_Instance-Group_Discrimination_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2008.03813"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Unsupervised_Feature_Learning_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="http://people.eecs.berkeley.edu/~xdwang/projects/CLD/"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Scene-aware Generative Network for Human Motion Synthesis </span> 
                                <br />
                                <span class="text-500">
                                J. Wang, S. Yan, B. Dai, D. Lin <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Scene-Aware_Generative_Network_CVPR_2021_supplemental.zip"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="http://wangjingbo.top/papers/Posegeneration/Posegeneration.html"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="3"><strong>Thursday, June 24 <br /> 11:00 – 13:30</strong></td>
                                <td rowspan="3">Ten</td>
                                <td>
                                <span class="text-primary">Positional Encoding as Spatial Inductive Bias in GANs </span> 
                                <br />
                                <span class="text-500">
                                R. Xu, X. Wang, K. Chen, B. Zhou, C. C. Loy <br />  
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Positional_Encoding_As_Spatial_Inductive_Bias_in_GANs_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2012.05217"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Xu_Positional_Encoding_As_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://nbei.github.io/gan-pos-encoding.html"><span class="text-muted">Project Page</span></a>]
                                [<a href="https://www.youtube.com/watch?v=n6B01YqC1ng&feature=emb_title"><span class="text-muted">YouTube</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Audio-Driven Emotional Video Portraits </span> 
                                <br />
                                <span class="text-500">
                                X. Ji, H. Zhou, K. Wang, W. Wu, X. Cao, C. C. Loy, F. Xu  <br /> 
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.07452"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Ji_Audio-Driven_Emotional_Video_CVPR_2021_supplemental.zip"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://jixinya.github.io/projects/evp/"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">LiDAR-based Panoptic Segmentation via Dynamic Shifting Network</span> 
                                <br />
                                <span class="text-500">
                                F. Hong, H. Zhou, X. Zhu, H. Li, Z. Liu  <br />
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_LiDAR-Based_Panoptic_Segmentation_via_Dynamic_Shifting_Network_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2011.11964"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Hong_LiDAR-Based_Panoptic_Segmentation_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://github.com/hongfz16/DS-Net"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>

                            <tr>
                                <td rowspan="2"><strong>Thursday, June 24 <br /> 22:00  – 24:30</strong></td>
                                <td rowspan="2">Eleven</td>
                                <td>
                                <span class="text-primary">GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution </span> <strong>(Oral)</strong>
                                <br />
                                <span class="text-500">
                                K. C. K. Chan, X. Wang, X. Xu, J. Gu, C. C. Loy <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_GLEAN_Generative_Latent_Bank_for_Large-Factor_Image_Super-Resolution_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2012.00739"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Chan_GLEAN_Generative_Latent_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="../../project/glean/index.html"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                            <tr>
                                <td>
                                <span class="text-primary">Visually Informed Binaural Audio Generation without Binaural Audios </span> 
                                <br />
                                <span class="text-500">
                                X. Xu, H. Zhou, Z. Liu, B. Dai, X. Wang, D. Lin <br />   
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.pdf"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2104.06162"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Xu_Visually_Informed_Binaural_CVPR_2021_supplemental.pdf"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="https://sheldontsui.github.io/projects/PseudoBinaural"><span class="text-muted">Project Page</span></a>]
                                </td>
                            </tr>
                                                        
                            </tbody>
                        </table>
                        <hr/>
                    </div>
                </div>
            </section>
            <!-- End of Section -->            
                                   
        </main>
        <!-- End of Main Content -->


        <!-- Footer -->
        <footer class="footer text-white" style="background-image: url(../../assets/img/footer-bg.jpg)">
            <div class="container d-flex h-100">
                <div class="row flex-grow-1">
                    <div class="col-lg-3 pt-3 ext-l bg-secondary text-center text-lg-left">
                        <div class="d-flex flex-column h-100">
                            <div class="pt-5 pt-lg-8 pb-4">
                                <img src="../../assets/img/logo-small.png" alt="" width="108" class="mb-4" />
                                <p class="mb-4 mt-3 fs--1"><br />
                                Academic Block North <br />
                                Nanyang Technological University<br />
                                61 Nanyang Dr, Singapore 637335</p>
        
                                <p class="fs--1">
                                <span class="text-white"><i class="zmdi zmdi-email zmdi-hc-fw mr-1"></i>mmlab-contact at e.ntu.edu.sg</span><br />
                                <span class="text-white"><i class="zmdi zmdi-twitter zmdi-hc-fw mr-1"></i><a href="https://twitter.com/MMLabNTU" target="_blank" class="text-white">@MMLabNTU</a></span></p>
                            </div>
    
                            <!-- <ul class="mt-4 mt-lg-auto mb-5 mb-lg-0 list-unstyled list-inline">
                                <li class="mr-3 list-inline-item">
                                    <a href="https://twitter.com/MMLabNTU" target="_blank">
                                        <i class="zmdi zmdi-twitter text-white"></i>
                                    </a>
                                </li>
                            </ul> -->
                        </div>
                    </div>

                    <div class="col d-flex flex-column mb-2 mt-3 pl-lg-7">
                        <div class="row pt-5 pt-lg-8 pb-4 pb-lg-6">
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">Publications</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="../../publication_topic.html" class="text-white">By Topic</a></li>
                                    <li class="my-1"><a href="../../publication_year.html" class="text-white">By Year</a></li>
                                </ul>
                            </div>
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">About</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="../../research.html" class="text-white">Our Research</a></li>
                                    <li class="my-1"><a href="../../team.html" class="text-white">Team</a></li>
                                    <li class="my-1"><a href="../../careers.html" class="text-white">Join Us</a></li>
                                </ul>
                            </div>
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">Open Source</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="https://openmmlab.com/" target="_blank" class="text-white">OpenMMLab</a></li>
                                    <li class="my-1"><a href="../../downloads.html" class="text-white">Codes and Datasets</a></li>
                                </ul>
                            </div>
                        </div>

                        <div class="mt-auto d-flex justify-content-between">
                            <span class="fs--3 fs-lg--2">&copy; MMLab@NTU, 2021</span>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- End of Footer -->


        <!-- Core Javascripts -->
        <script src="../../assets/vendor/jquery/dist/jquery.min.js"></script>
        <script src="../../assets/vendor/popper.js/dist/umd/popper.min.js"></script>
        <script src="../../assets/vendor/bootstrap/dist/js/bootstrap.min.js"></script>

        <!-- Vendor Javascripts -->
        <script src="../../assets/vendor/rellax/rellax.min.js"></script>
        <script src="../../assets/vendor/@fancyapps/fancybox/dist/jquery.fancybox.min.js"></script>
        <script src="../../assets/vendor/sticky-kit/dist/sticky-kit.min.js"></script>
        <script src="../../assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
        <script src="../../assets/vendor/isotope-layout/dist/isotope.pkgd.min.js"></script>
        <script src="../../assets/vendor/isotope-packery/packery-mode.pkgd.min.js"></script>
        <script src="../../assets/vendor/aos/dist/aos.js"></script>

        <!-- Theme Javascripts -->
        <script src="../../assets/js/theme.js"></script>


    </body>
</html>