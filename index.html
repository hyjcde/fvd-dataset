<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <meta name="keywords" content="Chen Change Loy, Ziwei Liu, Bo Dai, Yixin Cao, Super-resolution, Deep Learning, Computer Vision, Convolutional Neural Network, Enhancement, Inpainting, Knowledge Distillation, Restoration, GAN, Generative Adversarial Networks, Generation, Manipulation, Editing, Object Detection, Segmentation, Recognition, Continual Learning, Domain Generalization, Self-Supervised Learning, Singapore, NTU, Nanyang Technological University, SCSE" />
        
        <!-- Page Title -->
        <title>Home | MMLab@NTU</title>

        <!-- Favicons -->
        <link rel="apple-touch-icon" sizes="180x180" href="./assets/img/favicons/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="./assets/img/favicons/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="./assets/img/favicons/favicon-16x16.png">
        <link rel="manifest" href="./assets/img/favicons/site.webmanifest">
        <link rel="mask-icon" href="./assets/img/favicons/safari-pinned-tab.svg" color="#f23838">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">

        <!-- Vendor Stylesheets -->
        <link href="https://fonts.googleapis.com/css?family=Oswald:300,400,500,700%7CRoboto:300,400,700" rel="stylesheet">
        <link href="./assets/vendor/material-design-iconic-font/dist/css/material-design-iconic-font.min.css" rel="stylesheet">
        <!-- <link href="./assets/vendor/owl.carousel/dist/assets/owl.carousel.min.css" rel="stylesheet"> -->
        <link href="./assets/vendor/@fortawesome/fontawesome-free/css/all.min.css" rel="stylesheet">
        <link href="./assets/vendor/@fancyapps/fancybox/dist/jquery.fancybox.min.css" rel="stylesheet">
        <!-- <link href="./assets/vendor/aos/dist/aos.css" rel="stylesheet"> -->

        <!-- Theme Stylesheets -->
        <link href="./assets/css/theme.css" rel="stylesheet">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-22940424-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-22940424-1');
        </script>
    </head>

    <body>
        <!-- Preloader -->
        <div class="preloader">
            <div class="spinner">
                <div class="circles"></div>
            </div>
        </div>
        <!-- End of Preloader -->


        <!-- Header -->
        <header class="spyre-navbar navbar navbar-expand-lg bg-secondary navbar-dark fixed-top align-items-center" data-transparent data-text-color="#ffffff">
            <div class="container">
                <a class="navbar-brand mr-lg-5 mr-xl-7" href="./index.html">
                    <img src="./assets/img/logo.png" class="d-none d-lg-block" alt="MMLab" width="183" />
                    <img src="./assets/img/logo.png" class="d-block d-lg-none" alt="MMLab" width="150" />
                </a>

                <!-— Desktop Menu -->
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="navbar-nav mr-auto">
                        <li class="pl-2 nav-item navbar-text"><a href="./index.html" class="nav-link">Home</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="./team.html" class="nav-link text-400">Team</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="./research.html" class="nav-link text-400">Research</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="./publication_topic.html" class="nav-link text-400">Publications</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="./downloads.html" class="nav-link text-400">Code | Datasets</a></li>
                        <li class="pl-5 nav-item navbar-text"><a href="./careers.html" class="nav-link text-400">Join Us</a></li>
                    </ul>
                </div>
                <!-— End of Desktop Menu -->

                <div class="menu-toggle d-block d-lg-none">
                    <div class="hamburger">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                    <div class="cross">
                        <span></span>
                        <span></span>
                    </div>
                </div>
            </div>

            <!-- Spyrenav Overlay -->
            <div class="spyre-navbar-overlay overlay-slide">
                <div class="container">
                    <div class="row">
                        <div class="spyre-navbar-nav-container col-md-6 col-lg-5 col-xl-4 bg-white ext-l">
                            <nav class="spyre-navbar-nav">
                                <ul class="spyre-nav">
                                    <li class="spyre-nav-item"><a href="./index.html" class="spyre-nav-link">Home</a></li>
                                    <li class="spyre-nav-item"><a href="./research.html" class="spyre-nav-link">Our Research</a></li>
                                    <li class="spyre-nav-item"><a href="./team.html" class="spyre-nav-link">Team</a></li>
                                    <li class="spyre-nav-item dropdown">
                                        <a href="#" class="spyre-nav-link dropdown-toggle" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications</a>
                                        <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                                            <li class="dropdown-menu-item"><a href="./publication_topic.html" class="dropdown-menu-link">By Topic</a></li>
                                            <li class="dropdown-menu-item"><a href="./publication_year.html" class="dropdown-menu-link">By Year</a></li>
                                        </ul>
                                    </li>
                                    <li class="spyre-nav-item"><a href="./downloads.html" class="spyre-nav-link">Code and Datasets</a></li>
                                    <li class="spyre-nav-item"><a href="./careers.html" class="spyre-nav-link">Join Us</a></li>
                                </ul>
                            </nav>
                        </div>
        
                        <div class="col-lg-7 col-xl-8 d-none d-md-block">
                            <div class="d-flex flex-column h-100">
                                <div class="d-flex h-100">
                                    <div class="align-self-center">
                                        <div class="text-uppercase"
                                            data-background-text="computer vision"
                                            data-color="#7079a2"
                                            data-opacity="0.02"
                                            data-font-size="85px"
                                            data-font-weight="500"
                                            data-offset-x="-5%"
                                            data-letter-spacing="5px"
                                        ></div>
                                        <div class="text-uppercase"
                                            data-background-text="mmlab"
                                            data-color="#7079a2"
                                            data-opacity="0.04"
                                            data-font-size="175px"
                                            data-font-weight="500"
                                            data-offset-x="29%"
                                            data-padding="7vh 0 2vh 0"
                                            data-letter-spacing="5px"
                                        ></div>
                                        <div class="text-uppercase"
                                            data-background-text="deep learning"
                                            data-color="#7079a2"
                                            data-opacity="0.03"
                                            data-font-size="140px"
                                            data-font-weight="500"
                                            data-offset-x="15%"
                                            data-letter-spacing="5px"
                                        ></div>
                                    </div>
                                </div>
                                
                                <div class="mt-auto">
                                    <ul class="nav flex-nowrap float-right">
                                        <li class="nav-item">
                                            <a class="nav-link px-2" href="https://twitter.com/MMLabNTU" target="_blank">
                                                <i class="zmdi zmdi-twitter text-white"></i>
                                            </a>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <!-- End of Spyrenav Overlay -->
        </header>
        <!-- End of Header -->


        <!-- Main Content -->
        <main class="main minh-100vh">
            <!-- Section -->
            <section class="py-0 overflow-hidden text-center">
                <div class="bg-container overlay overlay-60 parallax" data-rellax-percentage="0.5" style="background-image: url(./assets/img/backgrounds/bg-15.jpg)"></div>
                <div class="container">
                    <div class="row h-100vh justify-content-center align-items-center">
                        <div class="col-lg-8">
                            <h1 class="text-white fs-5 fs-lg-7" data-aos="fade-left" data-aos-duration="500">MMLab@NTU</h1>
                            <p class="mb-5 fs-lg-1 text-white" data-aos="fade-right" data-aos-delay="50" data-aos-duration="500">Multimedia Laboratory @ <br /> Nanyang Technological University<br />
                            Affiliated with S-Lab    
                            </p>
                            <div class="row justify-content-center">
                                <div class="col-auto">
                                    <a href="#section-4" class="btn btn-primary mx-2 px-5 mb-3" data-aos="fade-left" data-aos-delay="50" data-aos-duration="500" data-smooth-scroll data-smooth-scroll-hash="false">Explore</a>
                                </div>
                                <div class="col-auto">
                                    <a href="./research.html" class="btn btn-light px-5 mx-2" data-aos="fade-left" data-aos-delay="50" data-aos-duration="500">Our Research<i class="zmdi zmdi-long-arrow-right ml-2"></i></a>
                                </div>
                            </div>
                        </div>

                        <div class="move d-none d-lg-block">
                            <a href="#section-1" class="text-white" data-smooth-scroll data-smooth-scroll-hash="false">
                                <i class="zmdi zmdi-long-arrow-down zmdi-hc-2x"></i>
                            </a>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->

            <!-- Section -->
            <section id="section-1" class="py-0">
                <div class="container-fluid px-0">
                    <div class="row no-gutters">
                        <div class="col-md-6 py-6 py-lg-8 bg-blue-light overflow-hidden">
                            <div class="row h-100 align-items-center">
                                <div class="col px-5 px-lg-8 px-xl-10">
                                    <h3 class="my-0 fs-1 fw-medium text-primary text-uppercase text-center text-lg-left">About</h3>
                                    <h2 class="mb-4 fw-medium text-secondary text-center text-lg-left">MMLab@NTU</h2>
                                    <p class="mb-0 text-justify">MMLab@NTU was formed on the 1 August 2018, with a research focus on computer vision and deep learning. Its sister lab is <a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">MMLab@CUHK</a>. It is now a group with four faculty members and more than 35 members including research fellows, research assistants, and PhD students. <br /><br />
                                    </p>
                                    <p class="mb-0 text-justify"> Members in MMLab@NTU conduct research primarily in low-level vision, image and video understanding, creative content creation, 3D scene understanding and reconstruction. Have a look at the overview of <a href="./research.html">our research</a>. All publications are listed <a href="./publication_topic.html">here</a>. <br /><br />
                                    </p>
                                    <p class="mb-0 text-justify"> We are always looking for motivated PhD students, postdocs, research assistants who have the same interests like us. Check out the <a href="./careers.html">careers</a> page and follow us on <a href="https://twitter.com/MMLabNTU" target="_blank">Twitter</a>.
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6 py-8">
                            <div class="bg-container" style="background-image: url(./assets/img/images/ntu_arc.jpg);"></div>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section --> 

            <!-- Section -->
            <section id="section-2" class="pt-7 pb-0">
                <div class="container">
                    <div class="row no-gutters justify-content-between">
                        <div class="col-lg-6">
                            <div class="row">
                                <div class="col-lg-6">
                                    <div class="bg-secondary text-white mb-4 px-5 pt-2 pb-5">
                                        <div
                                            data-background-text="01"
                                            data-color="#ffffff"
                                            data-opacity="0.5"
                                            data-font-size="36px"
                                            data-font-weight="700"
                                            data-offset-x="-3.25rem"
                                        ></div>
                                        <h4 class="mb-4 fs-1 fw-medium">GOOGLE PhD FELLOWSHIP AWARD</h4>
                                        <p class="fs--1">09/2021: Kelvin Chan and Fangzhou Hong are awarded the very competitive and prestigious Google PhD Fellowship 2021 under the area “Machine Perception, Speech Technology and Computer Vision”!</p>
                                        <p class="mb-0 fs--1">
                                            <a href="https://research.google/outreach/phd-fellowship/recipients/" target="_blank" class="h6 fs--1 fw-bold text-uppercase text-primary float-right">View more<i class="zmdi zmdi-chevron-right pl-4"></i></a>
                                        </p>
                                    </div>
                                    <div class="bg-secondary text-white mb-4 px-5 pt-2 pb-5">
                                        <div
                                            data-background-text="02"
                                            data-color="#ffffff"
                                            data-opacity="0.5"
                                            data-font-size="36px"
                                            data-font-weight="700"
                                            data-offset-x="-3.25rem"
                                        ></div>
                                        <h4 class="mb-4 fs-1 fw-medium text-uppercase">ICCV 2021</h4>
                                        <p class="fs--1">07/2021: The team has a total of 11 papers accepted to ICCV 2021 (including one oral).</p>
                                        <p class="mb-0 fs--1">
                                            <a href="./conference/iccv2021/index.html" class="h6 fs--1 fw-bold text-uppercase text-primary float-right">View more<i class="zmdi zmdi-chevron-right pl-4"></i></a>
                                        </p>
                                    </div>
                                </div>
                                <div class="col-lg-6 mb-5 mb-lg-0">
                                    <div class="bg-secondary text-white mb-4 px-5 pt-2 pb-5">
                                        <div
                                            data-background-text="03"
                                            data-color="#ffffff"
                                            data-opacity="0.5"
                                            data-font-size="36px"
                                            data-font-weight="700"
                                            data-offset-x="-3.25rem"
                                        ></div>
                                        <h4 class="mb-4 fs-1 fw-medium text-uppercase">Three Champions in NTIRE 2021 Challenge</h4>
                                        <p class="fs--1">04/2021: NTIRE is the most competitive challenge for low-level vision tasks. With BasicVSR++, we won three Champions in the tracks for video super-resolution and quality enhancement of heavily compressed videos. Congrats to the team!</p>
                                        <p class="mb-0 fs--1">
                                            <a href="https://ckkelvinchan.github.io/projects/BasicVSR++/" target="_blank" class="h6 fs--1 fw-bold text-uppercase text-primary float-right">View more<i class="zmdi zmdi-chevron-right pl-4"></i></a>
                                        </p>
                                    </div>
                                    <div class="bg-secondary text-white mb-4 px-5 pt-2 pb-5">
                                        <div
                                            data-background-text="04"
                                            data-color="#ffffff"
                                            data-opacity="0.5"
                                            data-font-size="36px"
                                            data-font-weight="700"
                                            data-offset-x="-3.25rem"
                                        ></div>
                                        <h4 class="mb-4 fs-1 fw-medium text-uppercase">CVPR 2021</h4>
                                        <p class="fs--1">03/2021: The team has a total of 18 accepted to CVPR 2021 (including four orals).</p>
                                        <p class="mb-0 fs--1">
                                            <a href="./conference/cvpr2021/index.html" class="h6 fs--1 fw-bold text-uppercase text-primary float-right">View more<i class="zmdi zmdi-chevron-right pl-4"></i></a>
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-5">
                            <h3 class="my-0 fs-1 fw-medium text-primary text-uppercase text-center text-lg-left">Check Out</h3>
                            <h2 class="mb-5 fw-medium text-secondary text-uppercase text-center text-lg-left">News and Highlights</h2>

							<ul class="zmdi-hc-ul">
                                <li><i class="zmdi-hc-li zmdi zmdi-calendar"></i>09/2021: Six outstanding ICCV 2021 reviewers from our team! Congrats to <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li</a>, <a href="https://ckkelvinchan.github.io/" target="_blank">Kelvin Chan</a>, <a href="https://jingkang50.github.io/" target="_blank">Jingkang Yang</a>, <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ" target="_blank">Liang Pan</a>, <a href="https://scholar.google.com/citations?user=WrDKqIAAAAAJ" target="_blank">Zhongang Cai</a>, and <a href="https://kaiyangzhou.github.io/" target="_blank">Kaiyang Zhou</a>.</li>

                                <li><i class="zmdi-hc-li zmdi zmdi-calendar"></i>07/2021: We organize two challenges in conjunction with ICCV 2021 Sensing, Understanding and Synthesizing Humans Workshop, namely, MVP Point Cloud Challenge and Face Forgery Analysis Challenge. The deadline has passed. Check out the <a href="https://sense-human.github.io/" target="_blank">workshop</a> for more details.</li>

                                <li><i class="zmdi-hc-li zmdi zmdi-calendar"></i>05/2021: Five outstanding CVPR 2021 reviewers from our team! Congrats to <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li</a>, <a href="http://www.davidemoltisanti.com/research/" target="_blank">Davide Moltisanti</a>, <a href="https://sites.google.com/view/xiangyuxu" target="_blank">Xiangyu Xu</a>, <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ" target="_blank">Liang Pan</a>, and <a href="https://scholar.google.com/citations?user=yA9qseUAAAAJ" target="_blank">Jiahao Xie</a>.</li>

                                <li><i class="zmdi-hc-li zmdi zmdi-calendar"></i>03/2021: The team has a total of <a href="./conference/cvpr2021/index.html">18 papers</a> accepted to CVPR 2021 (including four orals).</li>
	                            
                                <li><i class="zmdi-hc-li zmdi zmdi-calendar"></i>01/2021: Two papers to appear in ICLR 2021.</li>
							</ul>

                            <p class="mb-4">
                                <a href="./news.html" class="h6 fs--1 fw-bold text-uppercase text-primary float-left">View more<i class="zmdi zmdi-chevron-right pl-4"></i></a>
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section --> 

            <!-- Section -->
            <section id="section-3" class="pt-7 pb-6">
                <div class="container">
                    <h3 class="my-0 fs-1 fw-medium text-primary text-uppercase text-center text-lg-left">Recent</h3>
                    <h2 class="mb-5 fw-medium text-secondary text-center text-lg-left">Projects</h2>
                    
                    <div class="row justify-content-center">
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./project/pathrestore/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/pathrestore.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <p>
                                <span class="text-primary">Path-Restore: Learning Network Path Selection for Image Restoration </span> 
                                <br />
                                <span class="text-500">
                                K. Yu, X. Wang, C. Dong, X. Tang, C. C. Loy<br /> 
                                IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021 <strong>(TPAMI)</strong><br />    
                                </span>
                                [<a href="https://doi.org/10.1109/TPAMI.2021.3096255" target="_blank"><span class="text-muted">DOI</span></a>]
                                [<a href="https://arxiv.org/abs/1904.10343" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="./project/pathrestore/index.html"><span class="text-muted">Project Page</span></a>]
                            </p>
                            <p class="text-justify">
                                We observe that some corrupted image regions are inherently easier to restore than others since the distortion and content vary within an image. To this end, we propose Path-Restore, a multi-path CNN with a pathfinder that can dynamically select an appropriate route for each image region. We train the pathfinder using reinforcement learning with a difficulty-regulated reward. This reward is related to the performance, complexity and "the difficulty of restoring a region". 
                            </p>
                        </div> 

                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./project/glean/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/glean.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <p>
                                <span class="text-primary">GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution </span> 
                                <br />
                                <span class="text-500">
                                K. C. K. Chan, X. Wang, X. Xu, J. Gu, C. C. Loy <br /> 
                                in Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021 <strong>(CVPR, Oral)</strong><br />    
                                </span>
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_GLEAN_Generative_Latent_Bank_for_Large-Factor_Image_Super-Resolution_CVPR_2021_paper.pdf" target="_blank"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2012.00739" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Chan_GLEAN_Generative_Latent_CVPR_2021_supplemental.pdf" target="_blank"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="./project/glean/index.html"><span class="text-muted">Project Page</span></a>]
                            </p>
                            <p class="text-justify">
                                We show that pre-trained Generative Adversarial Networks (GANs), e.g., StyleGAN, can be used as a latent bank to improve the restoration quality of large-factor image super-resolution (SR). Switching the bank allows the method to deal with images from diverse categories, e.g., cat, building, human face, and car. Images upscaled by GLEAN show clear improvements in terms of fidelity and texture faithfulness in comparison to existing methods. 
                            </p>
                        </div> 

                        <div class="col-lg-4 mb-4 mb-lg-6">
                            <a href="./project/texformer/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/3trans.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6">
                            <p>
                                <span class="text-primary">3D Human Texture Estimation from a Single Image with Transformers </span> 
                                <br />
                                <span class="text-500">
                                X. Xu, C. C. Loy <br /> 
                                in Proceedings of IEEE/CVF International Conference on Computer Vision, 2021 <strong>(ICCV, Oral)</strong><br />    
                                </span>
                                [<a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/iccv_2021_texformer.pdf" target="_blank"><span class="text-muted">PDF</span></a>]
                                [<a href="./project/texformer/index.html" target="_blank"><span class="text-muted">Project Page</span></a>]   
                            </p>
                            <p class="text-justify">
                                Texformer estimates high-quality 3D human texture from a single image. The Transformer-based method allows efficient information interchange between the image space and UV texture space.
                            </p>
                        </div>

                        <div class="col-lg-4 mb-4 mb-lg-6">
                            <a href="./project/ffl/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/ffl.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6">
                            <p>
                                <span class="text-primary">Focal Frequency Loss for Image Reconstruction and Synthesis </span> 
                                <br />
                                <span class="text-500">
                                L. Jiang, B. Dai, W. Wu, C. C. Loy <br /> 
                                in Proceedings of IEEE/CVF International Conference on Computer Vision, 2021 <strong>(ICCV)</strong><br />    
                                </span>
                                [<a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/iccv_2021_ffl.pdf" target="_blank"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2012.12821" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="./project/ffl/index.html" target="_blank"><span class="text-muted">Project Page</span></a>]
                            </p>
                            <p class="text-justify">
                                We show that narrowing gaps in the frequency domain can ameliorate image reconstruction and synthesis quality further. We propose a novel focal frequency loss, which allows a model to adaptively focus on frequency components that are hard to synthesize by down-weighting the easy ones. This objective function is complementary to existing spatial losses, offering great impedance against the loss of important frequency information due to the inherent bias of neural networks.
                            </p>
                        </div>

                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./project/fasa/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/fasa.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <p>
                                <span class="text-primary">FASA: Feature Augmentation and Sampling Adaptation for Long-Tailed Instance Segmentation </span> 
                                <br />
                                <span class="text-500">
                                Y. Zang, C. Huang, C. C. Loy <br /> 
                                in Proceedings of IEEE/CVF International Conference on Computer Vision, 2021 <strong>(ICCV)</strong><br />    
                                </span>
                                [<a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/iccv_2021_fasa.pdf" target="_blank"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2102.12867" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/iccv_2021_fasa_supp.pdf" target="_blank"><span class="text-muted">Supplementary Material</span></a>]
                                [<a href="./project/fasa/index.html" target="_blank"><span class="text-muted">Project Page</span></a>] 
                            </p>
                            <p class="text-justify">
                                We propose a simple yet effective method, <strong>F</strong>eature <strong>A</strong>ugmentation and <strong>S</strong>ampling <strong>A</strong>daptation (FASA), that addresses the data scarcity issue by augmenting the feature space especially for rare classes. FASA is a fast, generic method that can be easily plugged into standard or long-tailed segmentation frameworks, with consistent performance gains and little added cost.
                            </p>
                        </div>

                        <div class="col-lg-4 mb-4 mb-lg-6">
                            <a href="./project/talkedit/index.html" target="_blank" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/talkedit.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6">
                            <p>
                                <span class="text-primary">Talk-to-Edit: Fine-Grained Facial Editing via Dialog </span> 
                                <br />
                                <span class="text-500">
                                Y. Jiang,  Z. Huang, X. Pan, C. C. Loy, Z. Liu <br /> 
                                in Proceedings of IEEE/CVF International Conference on Computer Vision, 2021 <strong>(ICCV)</strong><br />    
                                </span>
                                [<a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/iccv_2021_talkedit.pdf" target="_blank"><span class="text-muted">PDF</span></a>]
                                [<a href="https://arxiv.org/abs/2109.04425" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="./project/talkedit/index.html" target="_blank"><span class="text-muted">Project Page</span></a>] 
                            </p>
                            <p class="text-justify">
                                We propose Talk-to-Edit, an interactive facial editing framework that performs fine-grained attribute manipulation through dialog between the user and the system. Unlike previous works that regard the editing as traversing straight lines in the latent space, here the fine-grained editing is formulated as finding a curving trajectory that respects fine-grained attribute landscape on the semantic field. 2) The curvature at each step is location-specific and determined by the input image as well as the users’ language requests.
                            </p>
                        </div>

                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./project/orl/index.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/teasers/orl.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                        </div>
                        <div class="col-lg-8 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <p>
                                <span class="text-primary">Unsupervised Object-Level Representation Learning from Scene Images </span> 
                                <br />
                                <span class="text-500">
                                J. Xie, X. Zhan, Z. Liu, Y. S. Ong, C. C. Loy <br /> 
                                Technical report, arXiv:2106.11952, 2021 <br />    
                                </span>
                                [<a href="https://arxiv.org/abs/2106.11952" target="_blank"><span class="text-muted">arXiv</span></a>]
                                [<a href="./project/orl/index.html"><span class="text-muted">Project Page</span></a>]
                            </p>
                            <p class="text-justify">
                                We introduce <strong>O</strong>bject-level <strong>R</strong>epresentation <strong>L</strong>earning (ORL), a new self-supervised learning framework towards scene images. Extensive experiments on COCO show that ORL significantly improves the performance of self-supervised learning on scene images, even surpassing supervised ImageNet pre-training on several downstream tasks.
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->

            <!-- Section -->
            <section class="py-8 py-md-11 overflow-hidden">
                <div class="bg-container parallax" data-rellax-percentage="0.5" style="background-image: url(./assets/img/images/deocclusion.jpg);"></div>
                <div class="container-fluid">
                    <div class="row align-items-center">
                        <div class="col">
                            <a data-fancybox href="https://www.youtube.com/watch?v=xIHCyyaB5gU" class="icond mx-auto align-items-center text"><i class="zmdi zmdi-play zmdi-hc-4x"></i></a>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->          

            <!-- Section -->
            <section id="section-4">
                <div class="container">
                    <h3 class="my-0 fs-1 fw-medium text-primary text-uppercase text-center text-lg-left">Explore</h3>
                    <h2 class="mb-5 fw-medium text-secondary text-center text-lg-left">MMLab@NTU</h2>
                    
                    <div class="row justify-content-center">
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./research.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/printscreens/research.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                            <h4 class="text-center"><a href="./research.html" class="text-body">Our Research</a></h4>
                        </div>
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./team.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/printscreens/team.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                            <h4 class="text-center"><a href="./team.html" class="text-body">Team</a></h4>
                        </div>                        
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./publication_topic.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/printscreens/publication_topic.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                            <h4 class="text-center">Publications by <a href="./publication_topic.html" class="text-body">Topic</a> | <a href="./publication_year.html" class="text-body">Year</a></h4>
                        </div>
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./downloads.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/printscreens/downloads.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                            <h4 class="text-center"><a href="./downloads.html" class="text-body">Code and Datasets</a></h4>
                        </div>
                        <div class="col-lg-4 mb-4 mb-lg-6" data-aos="fade-up" data-aos-duration="1000">
                            <a href="./careers.html" class="mb-3 d-block position-relative">
                                <div class="position-absolute d-flex justify-content-center align-items-center w-100 h-100 bg-secondary rounded text-white">
                                    <i class="fas fa-link fa-2x"></i>
                                </div>
                                <img src="./assets/img/printscreens/careers.jpg" alt="" class="position-relative img-fluid w-100 shadow-lg rounded opacity-1-hover" />
                            </a>
                            <h4 class="text-center"><a href="./careers.html" class="text-body">Join Us</a></h4>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->

            <!-- Section -->
            <section id="section-1" class="py-0">
                <div class="container-fluid px-0">
                    <div class="row no-gutters">
                        <div class="col-md-6 py-6 py-lg-8 bg-blue-light overflow-hidden">
                            <div class="row h-100 align-items-center">
                                <div class="col px-5 px-lg-8 px-xl-10">
                                    <h3 class="my-0 fs-1 fw-medium text-primary text-center text-lg-left">ICCV 2021 - The 3rd Workshop on</h3>
                                    <h2 class="mb-4 fw-medium text-secondary text-center text-lg-left"> Sensing, Understanding and Synthesizing Humans</h2>
                                    <p class="mb-0 text-justify">In our <a href="https://sense-human.github.io/" target="_blank">workshop</a> this year, we are organizing two exciting challenges. <br /><br />
                                    </p>
                                    <p class="mb-0 text-justify"> In <a href="https://competitions.codalab.org/competitions/33430" target="_blank">MVP Point Cloud Challenge</a>, you can compete with others using your point cloud completion and registration methods based on the newly proposed <a href="https://mvp-dataset.github.io/" target="_blank">MVP dataset</a>, a high-quality multi-view partial point cloud dataset. It contains over 100,000 high-quality scans of partial 3D shapes rendered from 26 uniformly distributed camera poses for each 3D CAD model.<br /><br />
                                    </p>
                                    <p class="mb-0 text-justify"> In <a href="https://competitions.codalab.org/competitions/33386" target="_blank">ForgeryNet: Face Forgery Analysis Challenge</a>, you will benchmark your anti-deepfake methods on the largest face forgery data <a href="https://yinanhe.github.io/projects/forgerynet.html" target="_blank">ForgeryNet</a>.<br /><br />
                                    </p>
                                    <p class="mb-0 text-justify"> Both challenges have the deadline on September 19, 2021. Great prizes up for grabs!
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6 py-8">
                            <div class="bg-container" style="background-image: url(./assets/img/images/forgerynet_logo.jpg);"></div>
                        </div>
                    </div>
                </div>
            </section>
            <!-- End of Section -->           
        </main>
        <!-- End of Main Content -->


        <!-- Footer -->
        <footer class="footer text-white" style="background-image: url(./assets/img/footer-bg.jpg)">
            <div class="container d-flex h-100">
                <div class="row flex-grow-1">
                    <div class="col-lg-3 pt-3 ext-l bg-secondary text-center text-lg-left">
                        <div class="d-flex flex-column h-100">
                            <div class="pt-5 pt-lg-8 pb-4">
                                <img src="./assets/img/logo-small.png" alt="" width="108" class="mb-4" />
                                <p class="mb-4 mt-3 fs--1"><br />
                                Academic Block North <br />
                                Nanyang Technological University<br />
                                61 Nanyang Dr, Singapore 637335</p>
        
                                <p class="fs--1">
                                <span class="text-white"><i class="zmdi zmdi-email zmdi-hc-fw mr-1"></i>mmlab-contact at e.ntu.edu.sg</span><br />
                                <span class="text-white"><i class="zmdi zmdi-twitter zmdi-hc-fw mr-1"></i><a href="https://twitter.com/MMLabNTU" target="_blank" class="text-white">@MMLabNTU</a></span></p>
                            </div>
    
                            <!-- <ul class="mt-4 mt-lg-auto mb-5 mb-lg-0 list-unstyled list-inline">
                                <li class="mr-3 list-inline-item">
                                    <a href="https://twitter.com/MMLabNTU" target="_blank">
                                        <i class="zmdi zmdi-twitter text-white"></i>
                                    </a>
                                </li>
                            </ul> -->
                        </div>
                    </div>

                    <div class="col d-flex flex-column mb-2 mt-3 pl-lg-7">
                        <div class="row pt-5 pt-lg-8 pb-4 pb-lg-6">
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">Publications</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="./publication_topic.html" class="text-white">By Topic</a></li>
                                    <li class="my-1"><a href="./publication_year.html" class="text-white">By Year</a></li>
                                </ul>
                            </div>
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">About</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="./research.html" class="text-white">Our Research</a></li>
                                    <li class="my-1"><a href="./team.html" class="text-white">Team</a></li>
                                    <li class="my-1"><a href="./careers.html" class="text-white">Join Us</a></li>
                                </ul>
                            </div>
                            <div class="col-6 col-lg-3">
                                <h6 class="mb-1 mb-lg-4 text-uppercase">Open Source</h6>
                                <ul class="pt-2 mb-5 fw-light list-unstyled">
                                    <li class="my-1"><a href="https://openmmlab.com/" target="_blank" class="text-white">OpenMMLab</a></li>
                                    <li class="my-1"><a href="./downloads.html" class="text-white">Code and Datasets</a></li>
                                </ul>
                            </div>
                        </div>

                        <div class="mt-auto d-flex justify-content-between">
                            <span class="fs--3 fs-lg--2">&copy; MMLab@NTU, 2021</span>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- End of Footer -->


        <!-- Core Javascripts -->
        <script src="./assets/vendor/jquery/dist/jquery.min.js"></script>
        <script src="./assets/vendor/popper.js/dist/umd/popper.min.js"></script>
        <script src="./assets/vendor/bootstrap/dist/js/bootstrap.min.js"></script>

        <!-- Vendor Javascripts -->
        <script src="./assets/vendor/rellax/rellax.min.js"></script>
        <script src="./assets/vendor/@fancyapps/fancybox/dist/jquery.fancybox.min.js"></script>
        <script src="./assets/vendor/sticky-kit/dist/sticky-kit.min.js"></script>
        <script src="./assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
        <script src="./assets/vendor/isotope-layout/dist/isotope.pkgd.min.js"></script>
        <script src="./assets/vendor/isotope-packery/packery-mode.pkgd.min.js"></script>
        <!-- <script src="./assets/vendor/aos/dist/aos.js"></script> -->

        <!-- Theme Javascripts -->
        <script src="./assets/js/theme.js"></script>
    </body>
</html>